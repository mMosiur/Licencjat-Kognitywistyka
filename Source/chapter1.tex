\chapter{Neuronaukowe korzenie uczenia maszynowego}

Już niedługo po pierwszych teoriach i propozycjach dotyczących maszyn przeprowadzających obliczenia przedstawiły się one jako ciekawa koncepcja dla filozofii umysłu i psychologii.
Maszyna Turinga ze swoimi możliwościami przetwarzania informacji oraz terminologia z nią związana stały się nową popularną metaforą działania umysłu.
Aktualnie prawie każdy większy dział nauk humanistycznych ma swój komputacjonistyczny odłam skupiający się na tym właśnie aspekcie jako wbudowanej cesze świata rzeczywistego.
Był to kolejny z trendów analogii i metafory w psychologii \cite{vroon1987man}, jednak z biegiem czasu przez wielu uważany za coraz bliższy prawdy.

Największą różnicą między możliwościami umysłu człowieka a tym, co w przyszłości zostanie nazwane komputerem była koncepcja uczenia się.
Pierwsze użycie sformułowania "uczenie maszynowe" przypisuje się Arturowi Samuelowi, który takim określeniem opisał algorytmy podejmujące decyzje bez wcześniejszego jawnego zaprogramowania ich do takiego ich wykonywania \cite{koza1996automated}.
Dzisiaj ten dział informatyki obudowuje wiele różnych paradygmatów takich algorytmów.
Najwcześniej używanym były algorytmy genetyczne inspirowane ewolucyjnym charakterem przyrody.

Tak jak psychologia czerpała z informatyki inspirację przy budowaniu metafory komputerowej, tak dziedzina uczenia maszynowego inspirowała się obecnymi w naturze zjawiskami wszelkiego rodzaju uczenia się.
Idea algorytmów genetycznych i programowania genetycznego została wyprowadzona jako przeniesienie teorii ewolucji w naturze.
Najbardziej fundamentalna jednostka popularnych dzisiaj sztucznych sieci neuronowych -- sztuczny neuron, czy perceptron -- zostały po raz pierwszy zaproponowane jako matematyczny model naśladujący działanie neuronu biologicznego \cite{mcculloch1943logical}.

Początkowo neuron McCullocha-Pittsa bezpośrednio odwzorowywał działanie biologicznego odpowiednika, w tym na przykład traktując wyjście modelu binarnie jako \emph{aktywne} lub \emph{nieaktywne}.
Później także podobnie jak w biologicznym układzie nerwowym złożonym ze skomplikowanej sieci neuronów zaczęto wykorzystywać perceptrony wielowarstwowe propagujące sygnał wgłąb modelu \cite{rosenblatt1961principles}.

Dodatkowo od strony neuronauki pokładano nadzieje, że rozwój tych sztucznych systemów wzorowanych na biologicznym układzie nerwowym pozwoli nam w lepszy sposób zrozumieć działanie mózgu.
Znacznie prostsze jest zrozumienie złożonego systemu poprzez zbudowanie go od podstaw niż próby wykorzystania inżynierii wstecznej na danych obserwacyjnych z nim związanych \cite{braitenberg1986vehicles}.

Obie dziedziny zaczęły się jednak od siebie coraz bardziej oddalać.
Rozwój uczenia maszynowego -- w tym przede wszystkim uczenia głębokiego -- opierał się na optymalizacji funkcji kosztu i odkryciach natury matematycznej z tym związanych \cite{sutskever2013importance}.
Mimo tego, że koncepcje podstawowe wykorzystane w sztucznych sieciach neuronowych były bezpośrednio zainspirowane biologicznymi odpowiednikami, szybko okazało się, że wprowadzane modyfikacje architektury i działania sieci znacznie poprawiają ich skuteczność.
Zmiany te jednak nie tylko nie były wynikiem przełożenia wiedzy neuronaukowej do uczenia maszynowego, ale przeciwnie -- odstępowały od podobieństwa do natury na rzecz złożonych modeli matematycznych oraz udogodnień i usprawnień z nich wynikających.
Binarna funkcja aktywacji -- podobna do zachowania neuronu biologicznego -- okazała się gorsza od funkcji liniowych \cite{minsky2017perceptrons}, a te znowu ustępowały funkcjom nieliniowym \cite{haykin1994neural}.
Nowe wykorzystywane funkcje były skuteczniejsze i efektywniejsze \cite{sharma2017activation} w rozwiązywaniu problemów poszukiwania minimum funkcji kosztu.
Z drugiej strony w neuronauce odkryto wiele typów komórek, stanów komórkowych, mechanizmów obliczeniowych i przechowywania informacji oraz obszarów mózgowych \cite{solari2011cognitive}.
Nacisk kładziony był raczej na strukturę i budowę mózgu oraz różnej skali elementów go budujących a sieci neuronowe zaczęły przyjmować raczej rolę potężnego, ale prostego narzędzia jak w każdej innej dziedzinie, bez większych czy mocniejszych powiązań.
